input {
    jdbc {
        jdbc_driver_library => "${LOGSTASH_JDBC_DRIVER_JAR_LOCATION}"
        jdbc_driver_class => "${LOGSTASH_JDBC_DRIVER}"
        jdbc_connection_string => "${LOGSTASH_JDBC_URL}"
        jdbc_user => "${LOGSTASH_JDBC_USERNAME}"
        jdbc_password => "${LOGSTASH_JDBC_PASSWORD}"
        schedule => "* * * * *"
        statement => "SELECT public.users.id, username, password, full_name, email, phone_number, image, accept_email, active, role_id, public.roles.name AS role_name FROM public.users LEFT JOIN public.roles ON public.users.role_id = public.roles.id"
    }
}

## Add your filters / logstash plugins configuration here
filter {
    aggregate {
        task_id => "%{id}"
        code => "
            map['id'] ||= event.get('id')
            map['username'] ||= event.get('username')
            map['password'] ||= event.get('password')
            map['full_name'] ||= event.get('full_name')
            map['email'] ||= event.get('email')
            map['phone_number'] ||= event.get('phone_number')
            map['image'] ||= event.get('image')
            map['accept_email'] ||= event.get('accept_email')
            map['active'] ||= event.get('active')
            map['role'] ||= {'id' => event.get('role_id'), 'name' => event.get('role_name')}
            event.cancel()
        "
        push_previous_map_as_event => true
    }
}

output {
	elasticsearch {
		hosts => "${LOGSTASH_ELASTICSEARCH_HOST}"
		user => "elastic"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
        index => "users"
        document_id => "%{[id]}"
        doc_as_upsert => true
	}
	stdout { codec => "json" }
}
